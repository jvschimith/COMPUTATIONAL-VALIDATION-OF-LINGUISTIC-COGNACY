import streamlit as st
import pandas as pd
import networkx as nx
import editdistance 
from node2vec import Node2Vec
from sklearn.manifold import TSNE
import plotly.express as px
from itertools import combinations
import warnings

# --- CONFIGURA√á√ÉO INICIAL STREAMLIT ---
st.set_page_config(layout="wide")
warnings.filterwarnings("ignore") # Ignora warnings

# ----------------------------------------------------------------------
# A. DADOS INICIAIS (Defaults para o Editor de Dados)
# ----------------------------------------------------------------------

# Mapeamento padr√£o de Fam√≠lias para inicializar o sidebar
DEFAULT_FAMILY_MAPPING = {
    'Arin': 'Yeniseiana', 
    'Xiongn√∫': 'Xiongn√∫/Huns (Foco)', 
    'Proto-Turkic': 'Controle (Turkic)', 
    'Huns': 'Xiongn√∫/Huns (Foco)', 
    'Ket': 'Yeniseiana',
    'Proto-Mongolic': 'Controle (Mongolic)'
}

# Dados de palavras padr√£o para inicializar o editor de dados
DEFAULT_WORDS_DATA = {
    'Conceito': ['√Ågua', 'Dois', 'P√°ssaro', 'Fogo', 'Dedo', 'Comer', 'Ovo', 'M√£e', 'Nariz', 'Dente'],
    'Arin': ['yit', 'kin', 'qun', 'si', 't≈´', 'ƒìsi', 'u≈õe', 'ami', 'qan', 'qan'],
    'Xiongn√∫': ['yyt', 'k‚Äôin', 'qun', 'sa', 't\'u', 'ƒìssi', 'use', 'amy', 'qani', 'qan'],
    'Proto-Turkic': ['su', 'eki', 'qu≈ü', 'ot', 'til', 'ye', 'yumu', 'ana', 'burun', 'ti≈°'],
    'Huns': ['yit', 'kin', 'cun', 'se', 'tu', 'esi', 'use', 'amy', 'qan', 'qann'],
    'Ket': ['u‚Äôl', 'qƒ´n', 'qun', 'sƒ´', 'd≈´', 'e‚Äôs', '≈´s', 'amƒ´', 'qan', 'qa'],
    'Proto-Mongolic': ['usu', 'qoyar', '≈°uŒ≥', 'Œ≥al', 'urŒ≥u', 'ide', '√∂nd√º', 'eke', 'qabar', 'sid√º']
}

# ----------------------------------------------------------------------
# B. FUN√á√ïES DE PROCESSAMENTO
# ----------------------------------------------------------------------

@st.cache_data
def calculate_pair_similarity(lang1_series, lang2_series):
    """Calcula a similaridade m√©dia normalizada por edit distance entre duas listas de palavras."""
    total_similarity_score = 0
    num_concepts = len(lang1_series)
    
    for word1, word2 in zip(lang1_series, lang2_series):
        dist = editdistance.eval(word1, word2)
        max_len = max(len(word1), len(word2), 1) 
        normalized_similarity = 1 - (dist / max_len)
        total_similarity_score += normalized_similarity
        
    avg_similarity = total_similarity_score / num_concepts
    # Multiplica por 20 para ter pesos de aresta mais vis√≠veis (escalonamento)
    final_weight = avg_similarity * 20 
    
    return final_weight


@st.cache_data
def generate_weighted_edges(df, languages):
    """Gera o DataFrame de arestas ponderadas (input para o Node2Vec)."""
    weighted_edges = []
    
    for lang1, lang2 in combinations(languages, 2):
        # Acessa as colunas de palavras no DataFrame de input
        weight = calculate_pair_similarity(df[lang1], df[lang2])
        weighted_edges.append({
            'Source': lang1,
            'Target': lang2,
            'Weight': round(weight, 2)
        })
        
    return pd.DataFrame(weighted_edges)


@st.cache_resource
def run_node2vec_analysis(input_df, family_mapping):
    """Executa a cria√ß√£o do grafo, Node2Vec e t-SNE."""

    # 1. Grafo
    G = nx.Graph()
    for index, row in input_df.iterrows():
        G.add_edge(row['Source'], row['Target'], weight=row['Weight'])

    # 2. Node2Vec 
    node2vec = Node2Vec(
        G,
        walk_length=20,
        num_walks=200,
        p=1, 
        q=1,
        weight_key='weight',
        workers=4 # Define o n√∫mero de threads
    )

    # 3. Word2Vec com API NOVA (vector_size) - Corrige o TypeError
    model = node2vec.fit(
        vector_size=64,   # Par√¢metro correto para Gensim 4.x
        window=10,
        min_count=1,
        sg=1,             # skip-gram
        batch_words=32,
        epochs=20
    )

    # 4. Extrai embeddings
    embeddings = {node: model.wv[node] for node in G.nodes()}
    embedding_df = pd.DataFrame.from_dict(embeddings, orient='index')
    embedding_df.index.name = 'L√≠ngua'

    # 5. t-SNE
    X = embedding_df.values
    language_labels = embedding_df.index.tolist()

    # Perplexity precisa ser menor que (N - 1)
    perplexity_val = min(5, len(G.nodes()) - 1)
    if perplexity_val <= 0:
        return pd.DataFrame()

    tsne = TSNE(
        n_components=2,
        perplexity=perplexity_val,
        random_state=42,
        n_iter=5000
    )

    X_tsne = tsne.fit_transform(X)

    tsne_df = pd.DataFrame(
        X_tsne,
        columns=['Componente 1 (t-SNE)', 'Componente 2 (t-SNE)'],
        index=language_labels
    )
    tsne_df['L√≠ngua'] = tsne_df.index

    # Classifica√ß√£o das fam√≠lias com base no input do usu√°rio
    def get_family(lang):
        return family_mapping.get(lang, 'Fam√≠lia Desconhecida')

    tsne_df['Fam√≠lia Lingu√≠stica'] = tsne_df['L√≠ngua'].apply(get_family)

    return tsne_df

# ----------------------------------------------------------------------
# C. INTERFACE DE USU√ÅRIO (Input)
# ----------------------------------------------------------------------

st.title("Valida√ß√£o da Hip√≥tese Lingu√≠stica via Node2Vec (Input Din√¢mico) üìä")
st.markdown("""
Use a barra lateral para configurar o mapeamento de l√≠nguas e edite a tabela abaixo para inserir seus dados de lexemas.
""")

# --- 1. Sidebar Input: Mapeamento Linguagem-Fam√≠lia ---
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√£o de Dados")
    st.subheader("1. Mapeamento Linguagem - Fam√≠lia")
    st.markdown("Defina a qual fam√≠lia cada l√≠ngua pertence. Adicione ou remova linhas conforme necess√°rio.")
    
    family_df_default = pd.DataFrame(
        list(DEFAULT_FAMILY_MAPPING.items()), 
        columns=['L√≠ngua', 'Fam√≠lia Lingu√≠stica']
    )
    
    family_df_input = st.data_editor(
        family_df_default,
        key="family_map_editor",
        num_rows="dynamic",
        use_container_width=True
    )

# Processa o mapeamento
if not family_df_input.empty:
    family_map = family_df_input.set_index('L√≠ngua')['Fam√≠lia Lingu√≠stica'].to_dict()
else:
    st.error("O mapeamento de Linguagem para Fam√≠lia n√£o pode estar vazio.")
    st.stop()
    
LANGUAGES = list(family_map.keys())

# --- 2. Main Input: Lexemas Fon√©ticos ---
st.header("1. An√°lise de Similaridade de Palavras (Feature Engineering)")
st.markdown("---")

st.subheader("1.1 Entrada de Dados: Lexemas Fon√©ticos (Edit√°vel)")
st.markdown(f"""
Edite a tabela. As colunas devem incluir o `Conceito` e as **{len(LANGUAGES)}** l√≠nguas definidas: {', '.join(LANGUAGES)}.
""")

words_df_input = st.data_editor(
    pd.DataFrame(DEFAULT_WORDS_DATA),
    key="words_data_editor",
    num_rows="dynamic",
    use_container_width=True,
)

# Verifica a integridade dos dados antes de prosseguir
required_columns = set(LANGUAGES)
available_columns = set(words_df_input.columns)

if not required_columns.issubset(available_columns):
    missing_cols = required_columns - available_columns
    st.error(f"Erro: A tabela de Lexemas est√° faltando as seguintes colunas de L√≠nguas definidas na sidebar: {', '.join(missing_cols)}")
    st.stop()

# ----------------------------------------------------------------------
# D. EXECU√á√ÉO DA AN√ÅLISE E OUTPUT
# ----------------------------------------------------------------------

# 1. Gera√ß√£o dos Pesos (Arestas Ponderadas)
try:
    languages_df = generate_weighted_edges(words_df_input, LANGUAGES)
except KeyError as e:
    st.error(f"Erro na gera√ß√£o de pesos. Verifique se as colunas das l√≠nguas na tabela de lexemas correspondem exatamente √†s l√≠nguas definidas na barra lateral. Detalhe do erro: {e}")
    st.stop()

st.subheader("1.2 Output: Pesos Calculados (Arestas Ponderadas)")
st.markdown("O valor de `Weight` (Peso) √© a pontua√ß√£o de proximidade de similaridade fon√©tica e √© o **input para o Node2Vec**.")
st.dataframe(languages_df, use_container_width=True)


st.header("2. Pipeline de Machine Learning e Prova Geom√©trica")
st.markdown("---")

# 2. Executa a An√°lise Node2Vec + t-SNE
tsne_results = run_node2vec_analysis(languages_df, family_map)

st.subheader("2.1 Visualiza√ß√£o: Agrupamento Node2Vec + t-SNE")
st.markdown("""

O grafo de dispers√£o mostra as l√≠nguas mapeadas em 2D. A proximidade f√≠sica reflete a **alta Similaridade de Cosseno** entre os *embeddings* de 64 dimens√µes.
""")

if not tsne_results.empty:
    fig = px.scatter(
        tsne_results,
        x='Componente 1 (t-SNE)',
        y='Componente 2 (t-SNE)',
        color='Fam√≠lia Lingu√≠stica',
        text='L√≠ngua',
        title="Agrupamento de L√≠nguas (Node2Vec Embeddings)",
        height=600,
        hover_data=['L√≠ngua', 'Fam√≠lia Lingu√≠stica']
    )
    fig.update_traces(textposition='top center')
    st.plotly_chart(fig, use_container_width=True)
else:
    st.error("N√£o foi poss√≠vel gerar resultados t-SNE. O n√∫mero de l√≠nguas pode ser insuficiente.")

st.subheader("2.2 Conclus√£o do Modelo")
st.markdown("""
A an√°lise fornece uma **prova geom√©trica computacional** da hip√≥tese ao observar o agrupamento das l√≠nguas no espa√ßo 2D. 
O resultado √© din√¢mico e depende dos seus dados de entrada (lexemas) e do mapeamento de fam√≠lias.
""")
